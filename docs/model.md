# ğŸ”¬ EspecificaÃ§Ã£o TÃ©cnica Detalhada - Modelo LSTM para PrevisÃ£o de AÃ§Ãµes

> ğŸ“š **NavegaÃ§Ã£o:** [â† Voltar para README](../README.md) | [ğŸ“– Ver Ãndice de Docs](README.md) | [ğŸ”Œ Ver API REST](api.md)

**SÃ­mbolo PadrÃ£o:** AAPL (Apple Inc.)  
**PerÃ­odo de Treinamento:** 2018-01-01 a 2025-12-31  
**VersÃ£o do Modelo:** V1.20260108 (Baseline)  
**Framework:** TensorFlow/Keras

---

## ğŸ“‹ SumÃ¡rio Executivo

Modelo de rede neural LSTM (Long Short-Term Memory) treinado para prever preÃ§os de fechamento de aÃ§Ãµes com base em dados histÃ³ricos OHLCV (Open, High, Low, Close, Volume, Adjusted Close). A arquitetura utiliza duas camadas LSTM com dropout e regularizaÃ§Ã£o L2 para evitar overfitting.

**Performance Final (AAPL 2018-2025):**
- **RÂ² (Teste):** ~85-93% (variaÃ§Ã£o explicada)
- **MAE (Teste):** ~$9-12 (erro mÃ©dio absoluto)
- **RMSE (Teste):** ~$12-15
- **MAPE (Teste):** ~3-4%

Este documento explica o pipeline de dados, arquitetura do modelo e treinamento em detalhes tÃ©cnicos.

**ğŸ“– Documentos Relacionados:**
- [API REST - Guia Completo](api.md) - Como usar o modelo em produÃ§Ã£o
- [README Principal](../README.md) - VisÃ£o geral do projeto
- [Ãndice de DocumentaÃ§Ã£o](README.md) - Todos os documentos

---

## ğŸ“ Arquitetura Detalhada

### Fluxo de Dados Completo

```
ENTRADA (Batch Size B)
    â†“
    â””â”€ Shape: (B, 60, 6)
       â€¢ B = nÃºmero de sequÃªncias no batch (padrÃ£o: 32)
       â€¢ 60 = timesteps (dias histÃ³ricos)
       â€¢ 6 = features (Open, High, Low, Close, Volume, Adj Close)
       â€¢ Valores: Normalizados [0, 1]

    â†“ LSTM Layer 1 (100 unidades)
    â”œâ”€ Input: (B, 60, 6)
    â”œâ”€ Processamento:
    â”‚  â”œâ”€ 100 cÃ©lulas LSTM independentes
    â”‚  â”œâ”€ Cada cÃ©lula processa todos os 60 timesteps
    â”‚  â”œâ”€ Cada cÃ©lula mantÃ©m estado interno (memory cell)
    â”‚  â”œâ”€ Return sequences = True â†’ saÃ­da inclui todos os timesteps
    â”œâ”€ Output: (B, 60, 100)
    â”œâ”€ L2 Regularization (0.003):
    â”‚  â””â”€ Penalty = 0.003 * sum(weightsÂ²)
    â””â”€ ParÃ¢metros:
       â””â”€ ~47K (100 * (6 + 100) * 4 gates)

    â†“ Dropout Layer 1 (25%)
    â”œâ”€ Durante treinamento: Remove 25% das ativaÃ§Ãµes aleatoriamente
    â”œâ”€ Durante inferÃªncia: Usa todas (escaladas automaticamente)
    â””â”€ Efeito: RegularizaÃ§Ã£o, evita co-adaptaÃ§Ã£o

    â†“ LSTM Layer 2 (50 unidades)
    â”œâ”€ Input: (B, 60, 100)
    â”œâ”€ Processamento:
    â”‚  â”œâ”€ 50 cÃ©lulas LSTM independentes
    â”‚  â”œâ”€ Processa 100 features de entrada
    â”‚  â””â”€ Return sequences = False â†’ saÃ­da Ã© last timestep
    â”œâ”€ Output: (B, 50)
    â”œâ”€ L2 Regularization (0.003)
    â””â”€ ParÃ¢metros:
       â””â”€ ~30K (50 * (100 + 50) * 4 gates)

    â†“ Dropout Layer 2 (25%)
    â”œâ”€ Remove 25% das 50 ativaÃ§Ãµes
    â””â”€ Output: (B, 50)

    â†“ Dense Layer (16 unidades, ReLU)
    â”œâ”€ TransformaÃ§Ã£o nÃ£o-linear:
    â”‚  â””â”€ output[i] = max(0, sum(input[j] * weight[i,j]) + bias[i])
    â”œâ”€ ReLU: max(0, x) â†’ introduz nÃ£o-linearidade
    â”œâ”€ Output: (B, 16)
    â”œâ”€ L2 Regularization (0.003)
    â””â”€ ParÃ¢metros:
       â””â”€ ~816 (16 * (50 + 1))

    â†“ Output Layer (1 unidade, Linear)
    â”œâ”€ TransformaÃ§Ã£o linear:
    â”‚  â””â”€ output = sum(input[i] * weight[i]) + bias
    â”œâ”€ Linear: Sem funÃ§Ã£o de ativaÃ§Ã£o (regressÃ£o contÃ­nua)
    â”œâ”€ Output: (B, 1)
    â”œâ”€ Valor: [0, 1] normalizado
    â””â”€ ParÃ¢metros:
       â””â”€ ~17 (1 * (16 + 1))

SAÃDA (PreÃ§o Previsto)
    â”œâ”€ Shape: (B, 1)
    â”œâ”€ Valores: [0, 1] normalizado
    â””â”€ PÃ³s-processamento: Inverter com scaler
       â””â”€ PreÃ§o real = scaler.inverse_transform()
       
Total de ParÃ¢metros: ~78,000
```

---

## ğŸ§  CÃ©lula LSTM: Como Funciona

### Mecanismo Interno

```
LSTM Cell em Timestep t:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                 â”‚
â”‚  Inputs:                                        â”‚
â”‚  â€¢ x_t: vetor de entrada (6 features)           â”‚
â”‚  â€¢ h_{t-1}: hidden state anterior (100)         â”‚
â”‚  â€¢ c_{t-1}: cell state anterior (100)           â”‚
â”‚                                                 â”‚
â”‚  OperaÃ§Ãµes (4 Gates):                           â”‚
â”‚                                                 â”‚
â”‚  1. Forget Gate: f_t = Ïƒ(W_f[h_{t-1}, x_t] + b_f)
â”‚     â†’ Controla quanto do passado Ã© esquecido    â”‚
â”‚     â†’ Ïƒ (sigmoid) dÃ¡ valores 0-1               â”‚
â”‚     â†’ 0 = esquecer tudo, 1 = lembrar tudo      â”‚
â”‚                                                 â”‚
â”‚  2. Input Gate: i_t = Ïƒ(W_i[h_{t-1}, x_t] + b_i)
â”‚     â†’ Controla quanto da entrada entra          â”‚
â”‚                                                 â”‚
â”‚  3. Candidate: CÌƒ_t = tanh(W_c[h_{t-1}, x_t] + b_c)
â”‚     â†’ Nova informaÃ§Ã£o candidata                 â”‚
â”‚     â†’ tanh dÃ¡ valores -1 a 1                   â”‚
â”‚                                                 â”‚
â”‚  4. Cell State Update: c_t = f_t âŠ™ c_{t-1} + i_t âŠ™ CÌƒ_t
â”‚     â†’ MemÃ³ria de longo prazo                    â”‚
â”‚     â†’ âŠ™ = multiplicaÃ§Ã£o elemento-wise          â”‚
â”‚     â†’ Esquece parte antiga + adiciona nova info â”‚
â”‚                                                 â”‚
â”‚  5. Output Gate: o_t = Ïƒ(W_o[h_{t-1}, x_t] + b_o)
â”‚     â†’ Controla saÃ­da                           â”‚
â”‚                                                 â”‚
â”‚  6. Hidden State: h_t = o_t âŠ™ tanh(c_t)
â”‚     â†’ SaÃ­da para prÃ³ximo timestep              â”‚
â”‚     â†’ Ã‰ o "output" da cÃ©lula                   â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Onde:
  Ïƒ = sigmoid (0-1, controla fluxo de informaÃ§Ã£o)
  tanh = (-1 a 1, pode "esquecer" valores antigos)
  âŠ™ = multiplicaÃ§Ã£o elemento-wise (Hadamard product)
  W, b = pesos e vieses (aprendidos durante treinamento)
```

### Por Que LSTM e NÃ£o RNN Simples?

| Aspecto | RNN Simples | LSTM |
|--------|-----------|------|
| **Janela efetiva** | ~5-10 timesteps | ~60+ timesteps |
| **Vanishing gradient** | Severo (âˆ‚h/âˆ‚h < 1)^60 â‰ˆ 0 | Mitigado (cell state) |
| **MemÃ³ria longa** | DifÃ­cil (esquece rÃ¡pido) | FÃ¡cil (memory cell) |
| **DependÃªncias** | Apenas curtas | Longas e curtas |
| **Backprop** | Gradientes "morrem" | Gradientes fluem |

**Exemplo PrÃ¡tico:**
- RNN: "Se preÃ§o subiu ontem, sobe hoje" (dependÃªncia curta)
- LSTM: "Se hÃ¡ 50 dias houve earnings positivos, hÃ¡ tendÃªncia de alta" (dependÃªncia longa)

---

## ğŸ“Š Pipeline de Dados

### 1. Coleta de Dados
**Classe:** `StockDataProcessor` ([src/scripts/data_processor.py](../src/scripts/data_processor.py))

```python
processor = StockDataProcessor('AAPL', '2018-01-01', '2025-12-31')
processed_df, lstm_data = processor.process_pipeline(
    sequence_length=60,
    train_ratio=0.7,
    val_ratio=0.2
)
```

**Features utilizadas (6 colunas):**

| # | Feature | DescriÃ§Ã£o | Tipo |
|---|---------|-----------|------|
| 1 | `Open` | PreÃ§o de abertura do dia | Float (USD) |
| 2 | `High` | PreÃ§o mÃ¡ximo do dia | Float (USD) |
| 3 | `Low` | PreÃ§o mÃ­nimo do dia | Float (USD) |
| 4 | `Close` | PreÃ§o de fechamento **(TARGET)** | Float (USD) |
| 5 | `Volume` | Volume negociado | Int64 |
| 6 | `Adj Close` | PreÃ§o ajustado por splits/dividendos | Float (USD) |

**Por que essas 6 features?**
- âœ… **OHLCV** Ã© o padrÃ£o da indÃºstria financeira
- âœ… Captura toda a informaÃ§Ã£o bÃ¡sica de preÃ§o
- âœ… `Adj Close` corrige distorÃ§Ãµes histÃ³ricas
- âœ… `Volume` indica forÃ§a/interesse no movimento
- âœ… Dados sempre disponÃ­veis (yfinance, APIs)

### 2. NormalizaÃ§Ã£o com MinMaxScaler

#### TransformaÃ§Ã£o Forward (Treinamento)

Para cada feature f:
```
X_normalized[f] = (X_raw[f] - X_min[f]) / (X_max[f] - X_min[f])
```

**Exemplo com Close (AAPL):**
```python
# Dados brutos histÃ³ricos (2018-2025)
X_raw['Close'] = [150, 180, 200, 250, 300, ...]
X_min['Close'] = 150  # MÃ­nimo histÃ³rico
X_max['Close'] = 300  # MÃ¡ximo histÃ³rico

# NormalizaÃ§Ã£o
X_normalized['Close'] = [
    (150-150)/(300-150) = 0.000,  # MÃ­nimo vira 0
    (180-150)/(300-150) = 0.200,
    (200-150)/(300-150) = 0.333,
    (250-150)/(300-150) = 0.667,
    (300-150)/(300-150) = 1.000   # MÃ¡ximo vira 1
]
```

#### TransformaÃ§Ã£o Inverse (InferÃªncia)

```
X_raw[f] = X_normalized[f] * (X_max[f] - X_min[f]) + X_min[f]

Exemplo:
y_pred_norm = 0.75  # PrevisÃ£o normalizada do modelo
y_pred_real = 0.75 * (300 - 150) + 150 
            = 0.75 * 150 + 150
            = 262.5  # PreÃ§o real em USD
```

**Arquivo Scaler Salvo:**
```python
# models/scaler.pkl
MinMaxScaler(
  feature_range=(0, 1),
  n_features_in_=6,
  feature_names_in_=['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close'],
  data_min_=[150.0, 148.0, 145.0, 150.0, 50000000.0, 150.0],
  data_max_=[300.0, 305.0, 298.0, 300.0, 500000000.0, 300.0],
  data_range_=[150.0, 157.0, 153.0, 150.0, 450000000.0, 150.0]
)
```

### 3. CriaÃ§Ã£o de SequÃªncias

#### Janelas Deslizantes (Sliding Windows)

```
Dados brutos (1500 dias, exemplo):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ t1  t2  t3  t4  t5  t6  ... t1499  t1500                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Com Sequence Length = 60:

SequÃªncia 1:  [t1:t60]    â†’ predict t61
SequÃªncia 2:  [t2:t61]    â†’ predict t62
SequÃªncia 3:  [t3:t62]    â†’ predict t63
...
SequÃªncia 1441: [t1441:t1500] â†’ predict t1501 (nÃ£o existe!)

Resultado:
  â€¢ 1440 sequÃªncias de 1500 dados (1500 - 60)
  â€¢ SobreposiÃ§Ã£o: 59/60 dias compartilhados entre sequÃªncias
  â€¢ Data Augmentation implÃ­cito (diferentes "visÃµes")
  â€¢ Cada dia participa de mÃºltiplas sequÃªncias
```

**CÃ³digo Simplificado:**
```python
sequence_length = 60
sequences = []

for i in range(len(data) - sequence_length):
    X_seq = data[i:i+sequence_length, :]  # 60 dias, 6 features
    y_target = data[i+sequence_length, 3]  # Dia 61, coluna Close
    sequences.append((X_seq, y_target))
```

### 4. Split de Dados (Temporal)

```
Total: 1440 sequÃªncias (exemplo)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TREINO (70%)  â”‚  VAL (20%)   â”‚ TESTE (10%) â”‚
â”‚   1008 seqs     â”‚  288 seqs    â”‚  144 seqs   â”‚
â”‚   2018-2023     â”‚  2023-2024   â”‚  2024-2025  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš ï¸ CRÃTICO: Split temporal (sem shuffle!)
   â€¢ Treino: Dados mais antigos
   â€¢ Teste: Dados mais recentes
   â€¢ Simula realidade (nÃ£o vemos futuro)
```

**Por que nÃ£o shuffle?**
- âŒ Shuffle misturaria passado/futuro â†’ data leakage
- âŒ Modelo veria "dados do futuro" durante treino
- âœ… Split temporal = Ãºnico vÃ¡lido para sÃ©ries temporais

### 5. SaÃ­das do Pipeline

`process_pipeline()` retorna:
```python
X_train, y_train, X_val, y_val, X_test, y_test, scaler, feature_names
```

**Shapes:**
- **X_train:** (1008, 60, 6) - SequÃªncias de treino
- **y_train:** (1008,) - Targets (Close normalizado)
- **X_val:** (288, 60, 6) - SequÃªncias de validaÃ§Ã£o
- **y_val:** (288,) - Targets de validaÃ§Ã£o
- **X_test:** (144, 60, 6) - SequÃªncias de teste
- **y_test:** (144,) - Targets de teste
- **scaler:** MinMaxScaler fitted (necessÃ¡rio para API)
- **feature_names:** ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']

## ğŸ—ï¸ Arquitetura do Modelo

### Estrutura (V1 Baseline)
**FunÃ§Ã£o:** `build_model()` em [src/scripts/utils_train.py](../src/scripts/utils_train.py)

```python
Input: (60, 6)  # 60 timesteps, 6 features
    â†“
LSTM(100, return_sequences=True, recurrent_dropout=0.0)
    â†“
Dropout(0.25)
    â†“
LSTM(50, return_sequences=False)
    â†“
Dropout(0.25)
    â†“
Dense(16, activation='relu', kernel_regularizer=l2(0.003))
    â†“
Dense(1)  # SaÃ­da: Close normalizado
```

### HiperparÃ¢metros (Baseline)
```python
model_config = {
    'sequence_length': 60,
    'lstm_units': [100, 50],
    'dropout_rate': 0.25,
    'recurrent_dropout': 0.0,
    'dense_units': 16,
    'learning_rate': 0.001,
    'batch_size': 32,
    'epochs': 100,
    'regularization_l2': 0.003,
    'early_stop_patience': 15,
    'reduce_lr_patience': 8,
    'train_ratio': 0.7,
    'val_ratio': 0.2
}
```

### CompilaÃ§Ã£o
- **Otimizador:** `Adam(learning_rate=0.001)`
- **Loss:** `mean_squared_error` (MSE)
- **MÃ©tricas:** `['mape']` (Mean Absolute Percentage Error)

### Callbacks de Treinamento
```python
EarlyStopping(
    monitor='val_loss',
    patience=15,
    restore_best_weights=True
)

ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=8,
    verbose=1
)
```

## ğŸ¯ Treinamento (via Notebook)

### Processo Completo
**Notebook:** [notebooks/02_treino.ipynb](../notebooks/02_treino.ipynb)

#### 1. ConfiguraÃ§Ã£o de HiperparÃ¢metros
```python
SYMBOL = 'AAPL'
START_DATE = '2018-01-01'
END_DATE = '2025-12-31'

model_config = {
    'sequence_length': 60,
    'lstm_units': [100, 50],
    'dropout_rate': 0.25,
    # ... (ver seÃ§Ã£o Arquitetura)
}
```

#### 2. Processamento de Dados
```python
processor = StockDataProcessor(SYMBOL, START_DATE, END_DATE)
processed_df, lstm_data = processor.process_pipeline(
    sequence_length=model_config['sequence_length'],
    train_ratio=model_config['train_ratio'],
    val_ratio=model_config['val_ratio']
)

X_train, y_train, X_val, y_val, X_test, y_test, scaler, feature_names = lstm_data
```

#### 3. ConstruÃ§Ã£o e Treinamento
```python
input_shape = (X_train.shape[1], X_train.shape[2])  # (60, 6)
model = build_model(model_config, input_shape)

history = model.fit(
    X_train, y_train,
    batch_size=32,
    epochs=100,
    validation_data=(X_val, y_val),
    callbacks=[early_stop, reduce_lr],
    verbose=1
)
```

#### 4. AvaliaÃ§Ã£o e MÃ©tricas
- **InversÃ£o de normalizaÃ§Ã£o:** `inverse_transform_predictions()`
- **CÃ¡lculo de mÃ©tricas:** MAE, RMSE, MAPE, RÂ²
- **ComparaÃ§Ã£o:** Treino vs ValidaÃ§Ã£o vs Teste

#### 5. MLflow Tracking
- **Experiment:** `LSTM_Stock_Prediction`
- **ParÃ¢metros:** Todos os valores de `model_config`
- **MÃ©tricas:** MAE, RMSE, MAPE, val_loss, RÂ²
- **Artefatos:**
  - Modelo: `mlflow.keras.log_model()`
  - Scaler: `scaler.pkl`
  - Plots: validaÃ§Ã£o, loss, resÃ­duos

#### 6. Salvamento de Artefatos
**Essenciais para API:**
- `models/lstm_model.keras` - Modelo treinado
- `models/scaler.pkl` - MinMaxScaler fitted

**DiagnÃ³stico (opcional):**
- `data/temp_plots/validation_plot.png`
- `data/temp_plots/loss_plot.png`
- `data/temp_plots/residuals_*.png`

### Como Treinar um Novo Modelo

1. **Abrir notebook:**
   ```bash
   # No VS Code: Open notebooks/02_treino.ipynb
   # Ou Jupyter: jupyter lab notebooks/02_treino.ipynb
   ```

2. **Ajustar hiperparÃ¢metros:** Editar cÃ©lula 3 (`model_config`)

3. **Executar todas as cÃ©lulas:** Run All (Ctrl+Shift+Enter)

4. **Verificar artefatos:**
   ```bash
   ls -lh models/
   # Deve mostrar lstm_model.keras e scaler.pkl
   ```

5. **Testar API:**
   ```bash
   make run-local  # Terminal 1
   make test-api   # Terminal 2
   ```

## ğŸ“ˆ MÃ©tricas de AvaliaÃ§Ã£o

### DefiniÃ§Ãµes
- **MAE (Mean Absolute Error):** Erro absoluto mÃ©dio em $ (quanto o modelo erra em mÃ©dia)
- **RMSE (Root Mean Squared Error):** Raiz do erro quadrÃ¡tico mÃ©dio (penaliza erros grandes)
- **MAPE (Mean Absolute Percentage Error):** Erro percentual mÃ©dio (ex: 3.84% = ~$10 de erro em $260)
- **RÂ² Score:** ProporÃ§Ã£o da variÃ¢ncia explicada (0-100%, quanto mais prÃ³ximo de 100% melhor)

### Resultados do Modelo Atual (V1 Baseline)
**AÃ§Ã£o:** AAPL (2018-2025) | **Data:** Jan 2026

| Conjunto   | MAE ($) | RMSE ($) | MAPE (%) | RÂ² Score (%) |
|------------|---------|----------|----------|-------------|
| **Treino** | $6.31   | $9.86    | 2.63%    | 99.28%      |
| **Val**    | $8.72   | $11.30   | 3.68%    | 93.31%      |
| **Teste**  | $9.15   | $12.46   | 3.84%    | 85.19%      |

### InterpretaÃ§Ã£o
- **RÂ² gap (Treino â†’ Teste):** 99.28% â†’ 85.19% = **14.09%**
  - âœ… **AceitÃ¡vel:** Gap < 20% indica bom equilÃ­brio (nÃ£o overfit severo)
  - Modelo generaliza bem para dados nÃ£o vistos

- **MAPE Teste: 3.84%**
  - PreÃ§o mÃ©dio AAPL ~$250 â†’ Erro mÃ©dio de ~$9.60
  - âœ… **Excelente:** < 5% Ã© considerado muito bom para previsÃ£o de aÃ§Ãµes

- **MAE crescente:** $6.31 â†’ $8.72 â†’ $9.15
  - Esperado: dados de teste sÃ£o os mais recentes (maior volatilidade)
  - Ainda dentro de limites aceitÃ¡veis

### Como Calcular
**FunÃ§Ã£o:** `calculate_metrics()` em [src/scripts/utils_train.py](../src/scripts/utils_train.py)

```python
def calculate_metrics(y_true, y_pred, split_name):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    r2 = r2_score(y_true, y_pred)
    
    return {
        'Split': split_name,
        'MAE ($)': mae,
        'RMSE ($)': rmse,
        'MAPE (%)': mape,
        'RÂ² Score': r2
    }
```

## ğŸ”§ Dicas de Hyperparameter Tuning

### ParÃ¢metros Principais

#### 1. Sequence Length (Janela Temporal)
```python
sequence_length: 40â€“100
```
- **Recomendado:** 60-80 dias (2-3 meses)
- **Menor (30-40):** Captura padrÃµes curto prazo, treina mais rÃ¡pido
- **Maior (80-100):** Captura tendÃªncias longas, requer mais dados
- **Trade-off:** Mais longo = menos samples de treino

#### 2. Arquitetura LSTM
```python
lstm_units: [[100, 50], [128, 64], [192, 128], [256, 128]]
```
- **Baseline:** [100, 50] - Bom equilÃ­brio
- **Mais complexo:** [256, 128] - Se tem muito dados (> 2000 dias)
- **Mais simples:** [64, 32] - Se tem pouco dados ou quer evitar overfit

#### 3. RegularizaÃ§Ã£o
```python
dropout_rate: 0.15â€“0.30  # Recomendado: 0.20-0.25
recurrent_dropout: 0.0â€“0.15  # Cuidado: pode desacelerar treino
regularization_l2: 0.001â€“0.005  # Recomendado: 0.003
```
- **Dropout alto (> 0.3):** Use se RÂ² treino >> RÂ² teste (overfit)
- **L2 alto (> 0.01):** Pode sub-ajustar, comece com 0.003

#### 4. Camada Dense Final
```python
dense_units: 16â€“64
```
- **16-32:** Geralmente suficiente
- **64+:** Se arquitetura LSTM Ã© grande (256+ units)

#### 5. OtimizaÃ§Ã£o
```python
learning_rate: [0.001, 0.0007, 0.0005, 0.0003]
batch_size: [16, 32, 64]
```
- **LR 0.001:** Baseline (Adam)
- **LR 0.0003-0.0005:** Use se loss oscilar muito
- **Batch 32:** Baseline
- **Batch 16:** Se pouco dados ou quer mais atualizaÃ§Ãµes
- **Batch 64:** Se muito dados e quer treino mais rÃ¡pido

#### 6. Callbacks
```python
early_stop_patience: 10â€“20  # Recomendado: 15
reduce_lr_patience: 5â€“10   # Recomendado: 8
reduce_lr_factor: 0.5       # Reduz LR pela metade
```

### EstratÃ©gia de Tuning

#### Passo 1: Baseline (ComeÃ§ar aqui)
```python
model_config = {
    'sequence_length': 60,
    'lstm_units': [100, 50],
    'dropout_rate': 0.25,
    'learning_rate': 0.001,
    'batch_size': 32,
}
```

#### Passo 2: Se Underfitting (RÂ² teste < 70%)
- âœ… Aumentar complexidade: `lstm_units = [128, 64]` ou `[192, 128]`
- âœ… Reduzir dropout: `dropout_rate = 0.15`
- âœ… Aumentar `sequence_length = 80`
- âœ… Mais Ã©pocas (se parou cedo)

#### Passo 3: Se Overfitting (RÂ² treino >> RÂ² teste, gap > 20%)
- âœ… Aumentar dropout: `dropout_rate = 0.30`
- âœ… Adicionar recurrent_dropout: `0.1`
- âœ… Aumentar L2: `regularization_l2 = 0.005`
- âœ… Reduzir complexidade: `lstm_units = [64, 32]`
- âœ… Early stopping mais agressivo: `patience = 10`

#### Passo 4: Ajuste Fino
- Testar learning rates menores: `0.0005`, `0.0003`
- Ajustar `dense_units`
- Experimentar `batch_size`

### Exemplo de Experimentos

| Experimento | LSTM Units | Dropout | LR    | Seq Len | RÂ² Teste | MAE ($) | Status |
|-------------|------------|---------|-------|---------|----------|---------|--------|
| Baseline    | [100, 50]  | 0.25    | 0.001 | 60      | 85.19%   | $9.15   | âœ… Bom  |
| Exp 1       | [128, 64]  | 0.25    | 0.001 | 60      | 87.32%   | $8.76   | âœ… Melhor|
| Exp 2       | [256, 128] | 0.25    | 0.001 | 60      | 84.12%   | $9.89   | âš ï¸ Overfit|
| Exp 3       | [128, 64]  | 0.30    | 0.0007| 80      | 88.15%   | $8.21   | âœ… Melhor!|
| Exp 4       | [64, 32]   | 0.20    | 0.001 | 60      | 79.45%   | $11.32  | âŒ Underfit|

### Monitoramento no MLflow

Todos os experimentos sÃ£o registrados automaticamente:
```bash
cd notebooks
mlflow ui --port 5000
# Acesse: http://localhost:5000
```

**Comparar experimentos:**
- Ordene por `mae` ou `r2_test` (menor/maior)
- Verifique grÃ¡ficos de loss e resÃ­duos
- Compare hiperparÃ¢metros dos top 3 modelos

---

## ğŸ“ PrÃ³ximos Passos

### Implementar em ProduÃ§Ã£o
ğŸ‘‰ Ver [API REST - Guia Completo](api.md) para:
- Como carregar o modelo treinado
- Endpoints disponÃ­veis
- Exemplos de integraÃ§Ã£o
- Troubleshooting de API

### Melhorar o Modelo
ğŸ“Š Experimente:
1. Ajustar hiperparÃ¢metros (ver [seÃ§Ã£o de Tuning](#ğŸ”§-dicas-de-hyperparameter-tuning))
2. Adicionar features tÃ©cnicas (RSI, MACD, etc.)
3. Testar com outras aÃ§Ãµes (TSLA, MSFT, GOOGL)
4. Aumentar sequence_length (80, 100 dias)

### Monitorar Resultados
ğŸ“ˆ Use MLflow:
```bash
cd notebooks
poetry run mlflow ui --port 5000
# Acesse: http://localhost:5000
```

---

## ğŸ“š DocumentaÃ§Ã£o Relacionada

- **[â† README Principal](../README.md)** - VisÃ£o geral e quick start
- **[ğŸ”Œ API REST](api.md)** - Como usar o modelo via API
- **[ğŸ“– Ãndice de Docs](README.md)** - Todas as documentaÃ§Ãµes

---

**Ãšltima AtualizaÃ§Ã£o:** 8 de Janeiro de 2026  
**VersÃ£o:** V1.20260108 (Baseline)  
**Status:** âœ… DocumentaÃ§Ã£o Completa