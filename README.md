# ğŸš€ LSTM Stock Price Prediction Model + API

## Tech Challenge Fase 4 - PosTech FIAP

**Status:** âœ… PRONTO PARA PRODUÃ‡ÃƒO  
**Performance:** RÂ² ~85-93% | MAE ~$9-12 | MAPE ~3-4%  
**API:** âœ… IMPLEMENTADA E TESTADA  
**Ãšltima AtualizaÃ§Ã£o:** 8 de Janeiro de 2026

---

## ğŸ“Œ VisÃ£o Geral

Modelo de Deep Learning (LSTM) para previsÃ£o de preÃ§os de aÃ§Ãµes com API REST completa. Treinado em dados histÃ³ricos OHLCV com normalizaÃ§Ã£o MinMaxScaler e arquitetura de 2 camadas LSTM.

### ğŸ¯ Objetivos Atendidos
- âœ… Coleta de Dados (Yahoo Finance via yfinance)
- âœ… PrÃ©-processamento e NormalizaÃ§Ã£o (MinMaxScaler)
- âœ… Modelo LSTM (2 layers, ~78K parÃ¢metros)
- âœ… Treinamento com Early Stopping
- âœ… AvaliaÃ§Ã£o (MAE, RMSE, MAPE, RÂ²)
- âœ… API REST (FastAPI)
- âœ… ContainerizaÃ§Ã£o (Docker)

### ğŸ§  Tecnologias
- **Framework ML:** TensorFlow/Keras 2.12+
- **API:** FastAPI 0.104+
- **Linguagem:** Python 3.11.5
- **ContainerizaÃ§Ã£o:** Docker
- **Cloud:** AWS ECR (opcional)

---

## ğŸš€ Quick Start - API

### OpÃ§Ã£o 1: Rodar Localmente (Recomendado)
```bash
# 1. Instalar dependÃªncias
poetry install

# 2. Iniciar API
make run-local
# ou: poetry run uvicorn src.api.main:app --host 0.0.0.0 --port 8000
```

### OpÃ§Ã£o 2: Com Docker
```bash
make docker-build
make docker-run
```

**Acesse:**
- ğŸŒ API: http://localhost:8000
- ğŸ“– Swagger UI: http://localhost:8000/docs
- ğŸ“š ReDoc: http://localhost:8000/redoc

### Testar a API

**Teste Local:**
```bash
# Terminal 1: Rodar API
make run-local

# Terminal 2: Testar com dados reais da AAPL
make test-api
```

**Teste AWS (Load Balancer):**
```bash
# OpÃ§Ã£o 1: Modo interativo (solicita URL)
make test-aws

# OpÃ§Ã£o 2: URL direto
make test-aws-url URL=http://lstm-alb-xxxx.sa-east-1.elb.amazonaws.com
```

ğŸ‘‰ **Guia completo:** [docs/api.md](docs/api.md)

---

## ğŸ“š DocumentaÃ§Ã£o

### ğŸ¯ Para ComeÃ§ar:

| Perfil | Documento | DescriÃ§Ã£o |
|--------|-----------|-----------|
| **ğŸ‘¨â€ğŸ’» Desenvolvedores** | [docs/api.md](docs/api.md) | Guia completo da API REST |
| **ğŸ§  Data Scientists** | [docs/model.md](docs/model.md) | Arquitetura, treinamento, tuning |
| **ğŸ‘¨â€ğŸ’¼ Gestores** | Este README | VisÃ£o geral e mÃ©tricas |

### ğŸ“– DocumentaÃ§Ã£o Completa:

1. **[docs/api.md](docs/api.md)** - API REST (endpoints, exemplos, testes AWS, seguranÃ§a)
2. **[docs/model.md](docs/model.md)** - Modelo LSTM (arquitetura detalhada, matemÃ¡tica, tuning)
3. **[docs/README.md](docs/README.md)** - Ãndice da documentaÃ§Ã£o
4. **[.env.example](.env.example)** - Template de variÃ¡veis de ambiente

---

## ğŸ“Š Desempenho do Modelo

### MÃ©tricas (Exemplo: AAPL 2018-2025)

| Conjunto | RÂ² Score | MAE ($) | RMSE ($) | MAPE (%) |
|----------|----------|---------|----------|----------|
| **Treino** | 99.28% | $6.31 | $9.86 | 2.63% |
| **ValidaÃ§Ã£o** | 93.31% | $8.72 | $11.30 | 3.68% |
| **Teste** | 85.19% | $9.15 | $12.46 | 3.84% |

### InterpretaÃ§Ã£o
- âœ… **RÂ² Teste: 85.19%** - Excelente (explica 85% da variaÃ§Ã£o)
- âœ… **MAE: $9.15** - Erro mÃ©dio pequeno (~3.7% do preÃ§o mÃ©dio)
- âœ… **Gap Treinoâ†’Teste: 14%** - Baixo overfitting
- âœ… **MAPE: 3.84%** - Muito bom para sÃ©ries financeiras

### Arquitetura
```
Input (60 dias, 6 features)
    â†“
LSTM(100) + Dropout(0.25)
    â†“
LSTM(50) + Dropout(0.25)
    â†“
Dense(16, ReLU) + L2(0.003)
    â†“
Output(1) - PreÃ§o previsto
```

**Features utilizadas (6):** Open, High, Low, Close, Volume, Adj Close  
**Total de parÃ¢metros:** ~78,000  
**NormalizaÃ§Ã£o:** MinMaxScaler [0, 1]

---

## ğŸ› ï¸ Setup de Desenvolvimento

### PrÃ©-requisitos
1. **pyenv** (gerenciador de versÃ£o Python):
   ```bash
   # macOS (Homebrew)
   brew install pyenv
   
   # Linux (Ubuntu/Debian)
   curl https://pyenv.run | bash
   ```
   
2. **Python 3.11.5** (via pyenv):
   ```bash
   pyenv install 3.11.5
   pyenv local 3.11.5  # Define versÃ£o para este projeto
   python --version    # Verifica (deve ser 3.11.5)
   ```
   > O arquivo `.python-version` garante que todos usem a mesma versÃ£o.

3. **Poetry** (gerenciador de dependÃªncias):
   ```bash
   pip install poetry
   poetry install      # Instala dependÃªncias do pyproject.toml
   ```

### ExecuÃ§Ã£o Local

```bash
# 1. Ativar ambiente Poetry
poetry shell

# 2. OpÃ§Ã£o A: Treinar novo modelo
# Abra notebooks/02_treino.ipynb no VS Code/Jupyter
# Execute todas as cÃ©lulas sequencialmente
# Artefatos salvos em: models/lstm_model.keras, models/scaler.pkl

# 2. OpÃ§Ã£o B: Usar modelo existente + API
make run-local

# 3. Testar API (em outro terminal)
make test-api
```

### Comandos Ãšteis (Makefile)

```bash
# Desenvolvimento
make setup          # Instalar dependÃªncias com Poetry
make run-local      # Iniciar API localmente (porta 8000)
make test-api       # Testar API com dados reais da AAPL

# Docker
make docker-build   # Build da imagem Docker
make docker-run     # Rodar container localmente (porta 8000)

# AWS
make aws-login      # Autenticar no ECR
make aws-push       # Build + Tag + Push para ECR
make test-aws       # Testar API na AWS (modo interativo)
make test-aws-url   # Testar API na AWS com URL especÃ­fico
make git-push       # Git add + commit + push
```

> **Nota:** O treinamento Ã© feito via notebook interativo, nÃ£o via CLI

---

## ğŸ“ Estrutura do Projeto

```
lstm-predict/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py           # FastAPI app (endpoints /predict)
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ cache_manager.py  # Cache de dados histÃ³ricos
â”‚   â”‚   â”œâ”€â”€ data_processor.py # StockDataProcessor class
â”‚   â”‚   â”œâ”€â”€ utils_train.py    # build_model, mÃ©tricas, etc.
â”‚   â”‚   â”œâ”€â”€ teste_local.py    # Script de teste da API
â”‚   â”‚   â””â”€â”€ teste_aws.py      # Script de teste AWS
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploracao.ipynb   # AnÃ¡lise exploratÃ³ria
â”‚   â”œâ”€â”€ 02_treino.ipynb       # â­ Pipeline de treinamento
â”‚   â”œâ”€â”€ mlruns/               # MLflow tracking
â”‚   â””â”€â”€ data/cache/           # Cache de dados yfinance
â”œâ”€â”€ models/                    # ğŸ§  Modelo treinado
â”‚   â”œâ”€â”€ lstm_model.keras      # Modelo LSTM (~2 MB)
â”‚   â””â”€â”€ scaler.pkl            # MinMaxScaler fitted
â”œâ”€â”€ docs/                      # ğŸ“š DocumentaÃ§Ã£o completa
â”‚   â”œâ”€â”€ README.md             # Ãndice de documentaÃ§Ã£o
â”‚   â”œâ”€â”€ api.md                # â­ Guia completo da API
â”‚   â””â”€â”€ model.md              # â­ Guia do modelo LSTM
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Dados brutos (CSV)
â”‚   â””â”€â”€ temp_plots/           # GrÃ¡ficos temporÃ¡rios
â”œâ”€â”€ Dockerfile                # Container image
â”œâ”€â”€ Makefile                  # Comandos de desenvolvimento
â”œâ”€â”€ pyproject.toml            # Poetry dependencies
â”œâ”€â”€ .python-version           # Python 3.11.5
â””â”€â”€ README.md                 # Este arquivo
```

---

## ğŸ³ Docker

### Build e Run
```bash
# Build da imagem
make docker-build
# ou: docker build -t lstm-api .

# Run localmente
make docker-run
# ou: docker run -p 8000:8000 lstm-api
```

### Push para AWS ECR
```bash
# Autenticar
make aws-login

# Build + Tag + Push
make aws-push
```

---

## ğŸ“Š API - Exemplo de Uso

### Endpoint Principal: `POST /predict`

**Entrada:** 60 dias de dados OHLCV (nÃ£o normalizados)

```json
{
  "last_60_days": [
    [open, high, low, close, volume, adj_close],  // Dia 1
    [open, high, low, close, volume, adj_close],  // Dia 2
    ...
    [open, high, low, close, volume, adj_close]   // Dia 60
  ]
}
```

**SaÃ­da:** PrevisÃ£o do prÃ³ximo preÃ§o de fechamento

```json
{
  "prediction": 245.67
}
```

### Exemplo Completo (Python)

```python
import yfinance as yf
import requests

# 1. Baixar dados histÃ³ricos (Ãºltimos 3 meses)
df = yf.download('AAPL', period='3mo', auto_adjust=False, progress=False)

# 2. Preparar Ãºltimos 60 dias (6 features)
last_60 = df[['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']].tail(60)

# 3. Fazer requisiÃ§Ã£o
response = requests.post(
    "http://localhost:8000/predict",
    json={"last_60_days": last_60.values.tolist()}
)

# 4. Ver resultado
print(f"PreÃ§o atual: ${last_60['Close'].iloc[-1]:.2f}")
print(f"PrevisÃ£o:    ${response.json()['prediction']:.2f}")
```

### Teste RÃ¡pido

```bash
# Terminal 1: Iniciar API
make run-local

# Terminal 2: Testar com dados reais da AAPL
make test-api
```

**DocumentaÃ§Ã£o completa:** [docs/api.md](docs/api.md)

---

## ğŸ¯ Pipeline de Treinamento

### 1. Notebook Interativo (Recomendado)

Abra `notebooks/02_treino.ipynb` no VS Code/Jupyter e execute:

```python
# CÃ©lula 1: ConfiguraÃ§Ã£o
SYMBOL = 'AAPL'
START_DATE = '2018-01-01'
END_DATE = '2025-12-31'

model_config = {
    'sequence_length': 60,
    'lstm_units': [100, 50],
    'dropout_rate': 0.25,
    'learning_rate': 0.001,
    # ... ver notebook para config completa
}

# CÃ©lula 2: Processar dados
processor = StockDataProcessor(SYMBOL, START_DATE, END_DATE)
processed_df, lstm_data = processor.process_pipeline(...)

# CÃ©lula 3: Treinar modelo
model = build_model(model_config, input_shape)
history = model.fit(X_train, y_train, ...)

# CÃ©lula 4: Avaliar
y_test_pred = model.predict(X_test)
metrics = calculate_metrics(y_test, y_test_pred)

# CÃ©lula 5: Salvar artefatos
model.save('models/lstm_model.keras')
joblib.dump(scaler, 'models/scaler.pkl')
```

### 2. Artefatos Gerados

- âœ… `models/lstm_model.keras` - Modelo treinado (~2 MB)
- âœ… `models/scaler.pkl` - MinMaxScaler fitted
- âœ… `data/temp_plots/` - GrÃ¡ficos de diagnÃ³stico
- âœ… `notebooks/mlruns/` - Tracking MLflow

### 3. Visualizar Experimentos (MLflow)

```bash
cd notebooks
poetry run mlflow ui --port 5000
# Acesse: http://localhost:5000
```

**Guia completo:** [docs/model.md](docs/model.md)

---

## âœ… Requisitos Tech Challenge - Checklist

- âœ… **Coleta de Dados** - Yahoo Finance (yfinance)
- âœ… **PrÃ©-processamento** - MinMaxScaler, janelas de 60 dias
- âœ… **Modelo LSTM** - 2 camadas, ~78K parÃ¢metros
- âœ… **Treinamento** - Adam optimizer, Early Stopping, ReduceLROnPlateau
- âœ… **AvaliaÃ§Ã£o** - MAE, RMSE, MAPE, RÂ² em 3 conjuntos (treino/val/teste)
- âœ… **Salvamento** - Keras format (.keras) + Scaler (.pkl)
- âœ… **API REST** - FastAPI com endpoint /predict
- âœ… **DocumentaÃ§Ã£o** - README.md + docs/ completos
- âœ… **ContainerizaÃ§Ã£o** - Dockerfile + docker-compose
- âœ… **Testes** - Script de teste automatizado

---

## ğŸ“ Tecnologias Utilizadas

| Categoria | Tecnologia | VersÃ£o |
|-----------|------------|--------|
| **Linguagem** | Python | 3.11.5 |
| **ML Framework** | TensorFlow/Keras | 2.12+ |
| **API** | FastAPI | 0.104+ |
| **Dados** | yfinance | 0.2+ |
| **NormalizaÃ§Ã£o** | scikit-learn | 1.3+ |
| **Tracking** | MLflow | 2.9+ |
| **ContainerizaÃ§Ã£o** | Docker | 24+ |
| **OrquestraÃ§Ã£o** | Poetry | 1.7+ |

---

## ğŸ“ InformaÃ§Ãµes do Projeto

- **Criado:** Janeiro 2026
- **Status:** âœ… Completo e Validado
- **VersÃ£o:** V1.20260108 (Baseline)
- **PrÃ³ximos Passos:** Deploy em produÃ§Ã£o (AWS ECS)

---

## ï¿½ SeguranÃ§a e Dados SensÃ­veis

### âš ï¸ Arquivos que NÃƒO devem subir para o Git

O projeto jÃ¡ estÃ¡ configurado com `.gitignore` para proteger dados sensÃ­veis:

#### 1. Modelos Treinados (Arquivos Grandes)
```
models/                    # Modelos treinados (~2-50 MB)
â”œâ”€â”€ lstm_model.keras       # âŒ NÃƒO COMMITAR (arquivo grande)
â””â”€â”€ scaler.pkl             # âŒ NÃƒO COMMITAR
```

#### 2. Dados de Treinamento
```
data/                      # Dados brutos e processados
notebooks/data/            # Cache do yfinance
notebooks/mlruns/          # Experimentos MLflow
```

#### 3. Credenciais AWS
```
.env                       # âŒ NÃƒO COMMITAR (credenciais)
.env.local                 # âŒ NÃƒO COMMITAR
infra/terraform.tfvars     # âŒ NÃƒO COMMITAR (variÃ¡veis sensÃ­veis)
infra/.terraform/          # âŒ NÃƒO COMMITAR (estado local)
infra/*.tfstate*           # âŒ NÃƒO COMMITAR (estado Terraform)
```

#### 4. ConfiguraÃ§Ãµes IDE/Locais
```
.vscode/                   # ConfiguraÃ§Ãµes pessoais do editor
.idea/                     # ConfiguraÃ§Ãµes PyCharm
__pycache__/               # Cache Python
*.log                      # Logs
```

### âœ… Como Configurar Dados SensÃ­veis Localmente

#### OpÃ§Ã£o 1: VariÃ¡veis de Ambiente (Recomendado)

**Crie um arquivo `.env` na raiz do projeto:**
```bash
# .env (NÃƒO COMMITAR)
AWS_PROFILE=default
AWS_REGION=sa-east-1
AWS_ACCOUNT_ID=123456789012
LOAD_BALANCER_URL=http://lstm-alb-xxxx.sa-east-1.elb.amazonaws.com
```

**Carregue no cÃ³digo:**
```python
from dotenv import load_dotenv
import os

load_dotenv()
aws_account = os.getenv('AWS_ACCOUNT_ID')
```

#### OpÃ§Ã£o 2: AWS CLI Profile

**Configure suas credenciais AWS:**
```bash
# Configurar credenciais (interativo)
aws configure --profile lstm-api

# Ou editar manualmente
vim ~/.aws/credentials
```

**ConteÃºdo de `~/.aws/credentials`:**
```ini
[lstm-api]
aws_access_key_id = SEU_ACCESS_KEY
aws_secret_access_key = SUA_SECRET_KEY
region = sa-east-1
```

**Usar no Makefile:**
```bash
make aws-login AWS_PROFILE=lstm-api
```

#### OpÃ§Ã£o 3: Terraform Variables

**Crie `infra/terraform.tfvars` (NÃƒO COMMITAR):**
```hcl
aws_region     = "sa-east-1"
project_name   = "lstm-api"
environment    = "production"
ecr_repository = "lstm-api"
```

### ğŸ” Boas PrÃ¡ticas de SeguranÃ§a

1. **âœ… SEMPRE** verifique antes de commitar:
   ```bash
   git status  # Ver arquivos staged
   git diff    # Ver mudanÃ§as
   ```

2. **âœ… NUNCA** commite:
   - Credenciais AWS (access keys, secret keys)
   - URLs de produÃ§Ã£o com tokens
   - Arquivos `.env` ou `.tfvars`
   - Modelos treinados (use Git LFS ou S3)

3. **âœ… USE** secrets managers para produÃ§Ã£o:
   - AWS Secrets Manager
   - AWS Systems Manager Parameter Store
   - HashiCorp Vault

4. **âœ… ROTACIONE** credenciais regularmente:
   ```bash
   aws iam create-access-key --user-name lstm-api
   aws iam delete-access-key --access-key-id OLD_KEY
   ```

### ğŸ“¦ Como Compartilhar Modelos Treinados

**OpÃ§Ã£o 1: AWS S3 (Recomendado para produÃ§Ã£o)**
```bash
# Upload
aws s3 cp models/lstm_model.keras s3://seu-bucket/models/
aws s3 cp models/scaler.pkl s3://seu-bucket/models/

# Download (outro dev)
aws s3 cp s3://seu-bucket/models/lstm_model.keras models/
aws s3 cp s3://seu-bucket/models/scaler.pkl models/
```

**OpÃ§Ã£o 2: Git LFS (para arquivos grandes)**
```bash
# Instalar Git LFS
git lfs install

# Rastrear modelos
git lfs track "*.keras"
git lfs track "*.pkl"

# Commitar normalmente
git add .gitattributes models/
git commit -m "Add trained models"
```

**OpÃ§Ã£o 3: Google Drive/Dropbox (desenvolvimento)**
- Compartilhe link do arquivo
- Equipe baixa manualmente para `models/`

### ğŸš¨ Vazou Credenciais no Git?

**AÃ§Ã£o Imediata:**
```bash
# 1. Rotacionar credenciais IMEDIATAMENTE
aws iam create-access-key --user-name seu-usuario
aws iam delete-access-key --access-key-id CHAVE_VAZADA

# 2. Remover do histÃ³rico Git (use git-filter-repo)
pip install git-filter-repo
git filter-repo --path .env --invert-paths

# 3. Force push (CUIDADO: coordene com equipe)
git push origin --force --all
```

---

## ï¿½ğŸ“ Suporte e Contato

### Para Diferentes Perfis

| VocÃª Ã©... | Leia... | PrÃ³ximos Passos |
|-----------|---------|-----------------|
| ğŸ‘¨â€ğŸ’¼ **Gestor/PM** | Este README | Ver mÃ©tricas de desempenho |
| ğŸ‘¨â€ğŸ’» **Desenvolvedor** | [docs/api.md](docs/api.md) | Implementar integraÃ§Ã£o |
| ğŸ§  **Data Scientist** | [docs/model.md](docs/model.md) | Experimentar tuning |
| ğŸš€ **DevOps** | Makefile + Dockerfile | Configurar deploy |

### Recursos Ãšteis

- **Swagger UI:** http://localhost:8000/docs (API interativa)
- **ReDoc:** http://localhost:8000/redoc (documentaÃ§Ã£o alternativa)
- **MLflow UI:** http://localhost:5000 (tracking de experimentos)

### Problemas Comuns

1. **API nÃ£o inicia:** Verifique se porta 8000 estÃ¡ livre
2. **Erro de modelo:** Certifique-se que `models/lstm_model.keras` existe
3. **MLflow nÃ£o abre:** Verifique se estÃ¡ no diretÃ³rio `notebooks/`
4. **Credenciais AWS:** Configure via `aws configure` ou arquivo `.env`
5. **Load Balancer URL:** Obtenha no AWS Console (EC2 â†’ Load Balancers)

---

**Ãšltima AtualizaÃ§Ã£o:** 8 de Janeiro de 2026  
**Status:** âœ… PRONTO PARA PRODUÃ‡ÃƒO  
**Tech Challenge Fase 4 - PosTech FIAP**
